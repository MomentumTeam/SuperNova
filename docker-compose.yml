version: '3.8'
services:
  mongo:
    image: mongo:latest
    container_name: mongo
    environment:
      - PUID=1000
      - PGID=1000
    volumes:
      - ./data/db:/data/db
    ports:
      - 27017:27017
    restart: unless-stopped

  redis:
    image: redis:alpine
    container_name: redis
    command: redis-server --appendonly yes --requirepass "mozart"
    volumes:
      - ./data/data:/data
    ports:
      - 6379:6379
    restart: unless-stopped

  spike-service:
    image: spike-service
    build: ./spike-service
    env_file:
      - ./supernova.env
    ports:
      - '8080:8080'
    depends_on:
      - redis
    environment:
      - SS_REDIS_HOST=redis
      - SS_REDIS_PORT=6379
      - SS_REDIS_PASSWORD=mozart
      - SS_SPIKE_PUBLIC_KEY_FULL_PATH=/usr/src/app/src/utils/publickey.pem
      - SS_SHMUEL_AUDIENCE=shmuel
      - SS_KARTOFFEL_AUDIENCE=kartoffel

  request-service:
    image: request-service
    build: ./request-service
    env_file:
      - ./supernova.env
    ports:
      - '8081:8080'
    depends_on:
      - mongo
      - notification-service
    environment:
      - RS_MONGO_URL=mongodb://mongo:27017/supernova
      - RS_NS_URL=notification-service:8080
      - RS_TS_URL=tea-service:8080

  kartoffel-service:
    image: kartoffel-service
    build: ./kartoffel-service/
    env_file:
      - ./supernova.env
    ports:
      - '8082:8080'
    depends_on:
      - spike-service
    environment:
      - KS_USE_FAKER=true
      - KS_SS_URL=spike-service:8080

  producer-service:
    image: producer-service
    build: ./producer-service/
    env_file:
      - ./supernova.env
    ports:
      - '8083:8080'
    depends_on:
      - request-service
      - spike-service
    environment:
      - PS_QUEUE_API_URL=https://www.google.com
      - PS_RS_URL=request-service:8080
      - PS_DEV_MODE=true
      - PS_SS_URL=spike-service:8080
      - PS_SHMUEL_AUDIENCE=shmuel
      - PS_OLD_DOMAIN=oldDomain
      - PS_NEW_DOMAIN=newDomain

  notification-service:
    image: notification-service
    build: ./notification-service/
    env_file:
      - ./supernova.env
    ports:
      - '8084:8080'
    environment:
      - NS_MONGO_URL=mongodb://mongo:27017/supernova

  approver-service:
    image: approver-service
    build: ./approver-service/
    env_file:
      - ./supernova.env
    ports:
      - '8085:8080'
    depends_on:
      - request-service
      - kartoffel-service
    environment:
      - APS_MONGO_URL=mongodb://mongo:27017/supernova
      - APS_KS_URL=kartoffel-service:8080
      - APS_RS_URL=request-service:8080

  tea-service:
    image: tea-service
    build: ./tea-service/
    env_file:
      - ./supernova.env
    ports:
      - '8086:8080'
    environment:
      - TS_MONGO_URL=mongodb://mongo:27017/supernova
      - TS_KS_URL=kartoffel-service:8080

  bulk-service:
    image: bulk-service
    build: ./bulk-service/
    env_file:
      - ./supernova.env
    volumes:
      - bulk-files:/usr/src/app/bulk-files
    ports:
      - '8087:8080'
    depends_on:
      - request-service
      - tea-service
    environment:
      - BS_RS_URL=request-service:8080
      - BS_FOLDER_PATH=/usr/src/app/bulk-files

  execution-script:
    image: execution-script
    build: ./execution-script/
    env_file:
      - ./supernova.env
    depends_on:
      - request-service
      - producer-service
    environment:
      - EXS_RS_URL=request-service:8080
      - EXS_PS_URL=producer-service:8080
      - EXS_APS_URL=approver-service:8080
      - EXS_EVERY_HOUR=1
      - EXS_CRON_JOB=false

  whiteListSync-script:
    image: whitelistsync-script
    build: ./whiteListSync-script/
    env_file:
      - ./supernova.env
    depends_on:
      - approver-service
    environment:
      - WLS_APS_URL=approver-service:8080
      - WLS_HOUR=10
      - WLS_MINUTE=0
      - WLS_CRON_JOB=false

  authentication-service:
    image: authentication-service
    build: ./authentication-service/
    env_file:
      - ./supernova.env
    ports:
      - '9000:8080'
    depends_on:
      - kartoffel-service
    environment:
      - AS_SHRAGA_URL=https://shraga-prod.northeurope.cloudapp.azure.com
      - AS_CLIENT_ENDPOINT=http://localhost:3000
      - AS_KARTOFFEL_RPC_ENDPOINT=kartoffel-service:8080

  api-gateway:
    image: api-gateway
    build: ./api-gateway/
    env_file:
      - ./supernova.env
    volumes:
      - bulk-files:/usr/src/app/bulk-files
    ports:
      - '2000:8080'
    depends_on:
      - spike-service
      - kartoffel-service
      - producer-service
      - request-service
      - authentication-service
      - notification-service
      - approver-service
      - tea-service
      - bulk-service
      - apm-server
    environment:
      - GATEWAY_KS_URL=kartoffel-service:8080
      - GATEWAY_RS_URL=request-service:8080
      - GATEWAY_PS_URL=producer-service:8080
      - GATEWAY_AS_URL=http://localhost:9000
      - GATEWAY_BS_URL=bulk-service:8080
      - GATEWAY_APS_URL=approver-service:8080
      - GATEWAY_BS_FOLDER_PATH=/usr/src/app/bulk-files
      - GATEWAY_AUTHENTICATION_REQUIRED=true
      - GATEWAY_APM_URL=http://apm-server:8200

  # Kafka GUI
  kouncil:
    image: consdata/kouncil:latest
    ports:
      - "4001:8080"
    environment:
      bootstrapServers: 'kafka:29092'
    depends_on:
      - 'kafka'
  kafka:
    image: obsidiandynamics/kafka
    container_name: kafka
    ports:
      - '2181:2181'
      - '9092:9092'
    environment:
      KAFKA_LISTENERS: 'INTERNAL://:29092,EXTERNAL://:9092'
      KAFKA_ADVERTISED_LISTENERS: 'INTERNAL://kafka:29092,EXTERNAL://localhost:9092'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'INTERNAL'
      KAFKA_ZOOKEEPER_SESSION_TIMEOUT: '6000'
      KAFKA_RESTART_ATTEMPTS: '10'
      KAFKA_RESTART_DELAY: '5'
      ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL: '0'

  apm-server:
    image: docker.elastic.co/apm/apm-server:7.15.0
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    cap_add: ['CHOWN', 'DAC_OVERRIDE', 'SETGID', 'SETUID']
    cap_drop: ['ALL']
    ports:
      - 8200:8200
    command: >
      apm-server -e
        -E apm-server.rum.enabled=true
        -E setup.kibana.host=kibana:5601
        -E setup.template.settings.index.number_of_replicas=0
        -E apm-server.kibana.enabled=true
        -E apm-server.kibana.host=kibana:5601
        -E output.elasticsearch.hosts=["elasticsearch:9200"]
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0
    environment:
      - bootstrap.memory_lock=true
      - cluster.name=docker-cluster
      - cluster.routing.allocation.disk.threshold_enabled=false
      - discovery.type=single-node
      - ES_JAVA_OPTS=-XX:UseAVX=2 -Xms1g -Xmx1g
    ulimits:
      memlock:
        hard: -1
        soft: -1
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    healthcheck:
      interval: 20s
      retries: 10
      test: curl -s http://localhost:9200/_cluster/health | grep -vq '"status":"red"'

  kibana:
    image: docker.elastic.co/kibana/kibana:7.15.0
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
      - 5601:5601
    healthcheck:
      interval: 10s
      retries: 20
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:5601/api/status

volumes:
  bulk-files:
  esdata:
    driver: local
